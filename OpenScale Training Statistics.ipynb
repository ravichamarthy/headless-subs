{"cells":[{"cell_type":"markdown","metadata":{"id":"a87d0892-78b8-4746-b264-a6013b32eea7"},"source":["<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">\n"]},{"cell_type":"markdown","metadata":{"id":"e0b1e52e-77a4-425e-aa30-551600d097e1"},"source":["# Notebook for generating configuration for online subscriptions in IBM Watson OpenScale \n","\n","This notebook shows how to generate the following artefacts:\n","\n","1. Configuration JSON needed to configure an IBM Watson OpenScale online subscription. This JSON also contains information related to fairness configuration.\n","2. Drift Configuration Archive\n","\n","In order to use this notebook you need to do the following:\n","\n","1. Read the training data into a pandas dataframe called \"data_df\".  There is sample code below to show how this can be done if the training data is in IBM Cloud Object Storage. \n","2. Edit the below cells and provide the training data and fairness configuration information. \n","3. Run the notebook. It will generate a JSON and a download link for the JSON will be present at the very end of the notebook.\n","4. Download the JSON by clicking on the link and upload it in the IBM AI OpenScale GUI.\n","\n","If you have multiple models (deployments), you will have to repeat the above steps for each model (deployment).\n","\n","**Note:** Please restart the kernel after executing below cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7c270a4-5b44-490c-9075-5cda8bfa31c6"},"outputs":[],"source":["!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1\n","!pip install --upgrade ibm-watson-machine-learning --user | tail -n 1\n","!pip install pyspark --no-cache | tail -n 1\n","!pip install lime --no-cache | tail -n 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cc04a8af019944279556bf10e44b01fe"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"842cedefd44d45a7a11dcbc4dca21ffc"},"outputs":[],"source":["VERSION = \"5.3.5\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5242046560e940eb828045f6a504e852"},"outputs":[],"source":["WOS_CREDENTIALS = {\n","    \"url\": \"https://cpd-namespace1.apps.xxxxx..com\",\n","    \"username\": \"xxxxx\",\n","    \"password\": \"xxxxx\",\n","    \"version\": \"4.5\"\n","}\n","\n","WML_CREDENTIALS = WOS_CREDENTIALS.copy()\n","WML_CREDENTIALS[\"instance_id\"] = \"wml_local\""]},{"cell_type":"markdown","metadata":{"id":"c55210e68eca499fbd4c08377da841fd"},"source":["### For scoring the payload, used while generating the OpenScale Explainability and Drift archives."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"466e122be44d49429c3dc0198f7b7862"},"outputs":[],"source":["space_uid = 'd3fb73aa-e9cb-434f-b828-94e54b22a2a6'\n","deployment_uid = '10a9bc60-2b2f-4298-a0a3-e9301a66930d'"]},{"cell_type":"markdown","metadata":{"id":"d0fb9364-c381-459e-ab95-b7d10bc7254e"},"source":["# Read training data into a pandas data frame\n","\n","The first thing that you need to do is to read the training data into a pandas dataframe called \"data_df\".  Given below is sample code for doing this if the training data is in IBM Cloud Object Storage.  Please edit the below cell and make changes so that you can read your training data from the location where it is stored.  Please ensure that the training data is present in a data frame called \"data_df\".\n","\n","*Note: Pandas' read\\_csv method converts the columns to its data types. If you want the column type to not be interpreted, specify the dtype param to read_csv method in this cell. More on this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)*\n","\n","*Note: By default NA values will be dropped while computing training data distribution and training the drift archive. Please ensure to handle the NA values during Pandas' read\\_csv method*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c2aecd03767409c995f2a28beda888a"},"outputs":[],"source":["!rm german_credit_data_biased_training.csv\n","!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44db9b492d294ecfa46db7b80bd6398c"},"outputs":[],"source":["import pandas as pd\n","data_df=pd.read_csv (\"german_credit_data_biased_training.csv\")\n","data_df.head()"]},{"cell_type":"markdown","metadata":{"id":"10790444-aaa7-45fe-bd46-0cdf552709c1"},"source":["## Select the services for which configuration information needs to be generated\n","\n","This notebook has support to generaton configuration information related to fairness , explainability and drift service. The below can be used by the user to control service specific configuration information.\n","\n","Details of the service speicifc flags available:\n","\n","- enable_fairness : Flag to allow generation of fairness specific data distribution needed for configuration\n","- enable_explainability : Flag to allow generation of explainability specific information\n","- enable_drift: Flag to allow generation of drift detection model needed by drift service\n","\n","\n","service_configuration_support = { <br>\n","&nbsp;&nbsp;&nbsp;&nbsp;\"enable_fairness\": True,   \n","&nbsp;&nbsp;&nbsp;&nbsp;\"enable_explainability\": True,    \n","&nbsp;&nbsp;&nbsp;&nbsp;\"enable_drift\": False  \n","    }  \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9b7058a-226f-4817-bbf2-19e05be437f1"},"outputs":[],"source":["service_configuration_support = {\n","    \"enable_fairness\": True,\n","    \"enable_explainability\": True,\n","    \"enable_drift\": True\n","}"]},{"cell_type":"markdown","metadata":{"id":"0f81dddd-aa35-4908-9e5d-7968d5bf13ad"},"source":["## Training Data and Fairness Configuration Information\n","\n","Please provide information about the training data which is used to train the model.  In order to explain the configuration better, let us first consider an example of a Loan Processing Model which is trying to predict whether a person should get a loan or not. The training data for such a model will potentially contain the following columns: Credit_History, Monthly_salary, Applicant_Age, Loan_amount, Gender, Marital_status, Approval.  The \"Approval\" column contains the target field (label column or class label) and it can have the following values: \"Loan Granted\", \"Loan Denied\" or \"Loan Partially Granted\".  In this model we would like to ensure that the model is not biased against Gender=Female or Gender=Transgender.  We would also like to ensure that the model is not biased against the age group 15 to 30 years or age group 61 to 120 years. \n","\n","For the above model, the configuration information that we need to provide is:\n","\n","- class_label:  This is the name of the column in the training data dataframe (data_df) which contains the target field (also known as label column or the class label).  For the Loan Processing Model it would be \"Approval\".\n","- feature_columns: This is a comma separated list of column names which contain the feature column names (in the training data dataframe data_df).  For the Loan Processing model this would be: [\"Credit_History\", \"Monthly_salary\", \"Applicant_Age\", \"Loan_amount\", \"Gender\", \"Marital_status\"]\n","- categorical_columns: The list of column names (in data_df) which contain categorical values.  This should also include those columns which originally contained categorical values and have now been converted to numeric values. E.g., in the Loan Processing Model, the Marital_status column originally could have values: Single, Married, Divorced, Separated, Widowed.  These could have been converted to numeric values as follows: Single -> 0, Married -> 1, Divorced -> 2, Separated -> 3 and Widowed -> 4.  Thus the training data will have numeric values.  Please identify such columns as categorical.  Thus the list of categorical columns for the Loan Processing Model will be Credit_History, Gender and Marital_status. \n","\n","For the Loan Processing Model, this information will be provided as follows:\n","\n","training_data_info = { <br>\n","&nbsp;&nbsp;&nbsp;&nbsp;\"class_label\": \"Approval\",   \n","&nbsp;&nbsp;&nbsp;&nbsp;\"feature_columns\": [\"Credit_History\", \"Monthly_salary\", \"Applicant_Age\", \"Loan_amount\", \"Gender\", \"Marital_status\"],    \n","&nbsp;&nbsp;&nbsp;&nbsp;\"categorical_columns\": [\"Credit_History\",\"Gender\",\"Marital_status\"]   \n","    }  \n","    \n","  **Note:** Please note that categorical columns selected should be subset of feature columns. If there are no categorical columns among the feature columns selected , please set \"categorical_columns as [] or None\"\n","\n","Please edit the next cell and provide the above information for your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6676a1ba5d1143118ba4669f49cd2e8c"},"outputs":[],"source":["feature_columns=[\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n","cat_features=[\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n","class_label = \"Risk\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86d9a853-bb8d-40a0-b646-ca729100b3b3"},"outputs":[],"source":["training_data_info = {\n","    \"class_label\": class_label,\n","    \"feature_columns\": feature_columns,\n","    \"categorical_columns\": cat_features\n","}"]},{"cell_type":"markdown","metadata":{"id":"ed393655-bdac-46ab-954b-825421390637"},"source":["## Specify the Model Type\n","\n","In the next cell, specify the type of your model.  If your model is a binary classification model, then set the type to \"binary\". If it is a multi-class classifier then set the type to \"multiclass\". If it is a regression model (e.g., Linear Regression), then set it to \"regression\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"825754ab-1655-46fb-b806-5fb60d805b53"},"outputs":[],"source":["#Set model_type. Acceptable values are:[\"binary\",\"multiclass\",\"regression\"]\n","model_type = \"binary\""]},{"cell_type":"markdown","metadata":{"id":"fb9ae90d-457f-4786-a444-369912383a2d"},"source":["## Specify the Fairness Configuration\n","\n","You need to provide the following information for the fairness configuration: \n","\n","- fairness_attributes:  These are the attributes on which you wish to monitor fairness. In the Loan Processing Model, we wanted to ensure that the model is not baised against people of specific age group and people belonging to a specific gender.  Hence \"Applicant_Age\" and \"Gender\" will be the fairness attributes for the Loan Processing Model.\n","- With Indirect Bias support, you can also monitor protected attributes for fairness. The protected attributes are those attributes which are present in the training data but are not used to train the model. For example, sensitive attributes like gender, race, age may be present in training data but are not used for training. To check if there exists indirect bias with respect to some protected attribute due to possible correlation with some feature column, it can be specified in fairness configuration.\n","- type: The data type of the fairness attribute (e.g., float or int or double)\n","- minority:  The minority group for which we want to ensure that the model is not biased.  For the Loan Processing Model we wanted to ensure that the model is not biased against people in the age group 15 to 30 years & 61 to 120 years as well as people with Gender = Female or Gender = Transgender.  Hence the minority group for the fairness attribute \"Applicant_Age\" will be [15,30] and [61,120] and the minority group for fairness attribute \"Gender\" will be: \"Female\", \"Transgender\".  \n","- majority: The majority group for which the model might be biased towards.  For the Loan Processing Model, the majority group for the fairness attribute \"Applicant_Age\" will be [31,60], i.e., all the ages except the minority group.  For the fairness attribute \"Gender\" the majority group will be: \"Male\".  \n","- threshold:  The fairness threshold beyond which the Model is considered to be biased.  For the Loan Processing Model, let us say that the Bank is willing to tolerate the fact that Female and Transgender applicants will get upto 20% lesser approved loans than Males.  However, if the percentage is more than 20% then the Loan Processing Model will be considered biased.  E.g., if the percentage of approved loans for Female or Transgender applicants is say 25% lesser than those approved for Male applicants then the Model is to be considered as acting in a biased manner.  Thus for this scenario, the Fairness threshold will be 80 (100-20) (this is represented as a value normalized to 1, i.e., 0.8).  \n","\n","The fairness attributes for Loan Processing Model will be specified as:\n","\n","fairness_attributes = [  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"feature\": \"Applicant_Age\",   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"type\" : \"int\",   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"majority\": [ [31,60] ],   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"minority\": [ [15, 30], [61,120] ],  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"threshold\" : 0.8  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"feature\": \"Gender\",   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"type\" : \"string\",   \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"majority\": [\"Male\"],  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"minority\": [\"Female\", \"Transgender\"],  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"threshold\" : 0.8  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}  \n","&nbsp;&nbsp;&nbsp;&nbsp;]  \n","\n","Please edit the next cell and provide the fairness configuration for your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b09387a6-7cb7-4bb7-9e5a-43b7bc3f1d07"},"outputs":[],"source":["fairness_attributes = [{\n","                            \"type\" : \"string\",\n","                            \"feature\": \"Sex\", \n","                            \"majority\": ['female'],\n","                            \"minority\": ['male'],\n","                           \"threshold\": 0.98\n","                       }]"]},{"cell_type":"markdown","metadata":{"id":"d2a8a8f0-cb41-48f0-a3cd-ae391eca057a"},"source":["## Specify the Favorable and Unfavorable class values\n","\n","The second part of fairness configuration is about the favourable and unfavourable class values.  Recall that in the case of Loan Processing Model, the target field (label column or class label) can have the following values: \"Loan Granted\", \"Loan Denied\" and \"Loan Partially Granted\".  Out of these values \"Loan Granted\" and \"Loan Partially Granted\" can be considered as being favorable and \"Loan Denied\" is unfavorable.  In other words in order to measure fairness, we need to know the target field values which can be considered as being favourable and those values which can be considered as unfavourable.  \n","\n","For the Loan Prediction Model, the values can be specified as follows:\n","\n","parameters = {  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"favourable_class\" :  [ \"Loan Granted\", \"Loan Partially Granted\" ],  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"unfavourable_class\": [ \"Loan Denied\" ]  \n","&nbsp;&nbsp;&nbsp;&nbsp;}  \n","\n","In case of a regression models, the favourable and unfavourable classes will be ranges.  For example, for a model which predicts medicine dosage, the favorable outcome could be between 80 ml to 120 ml or between 5 ml to 20 ml whereas unfavorable outcome will be values between 21 ml to 79ml.  For such a model, the favorable and unfavorable values will be specified as follows:\n","     \n","parameters = {  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"favourable_class\" :  [ [5, 20], [80, 120] ],  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"unfavourable_class\": [ [21, 79] ]  \n","&nbsp;&nbsp;&nbsp;&nbsp;}  \n","\n","Please edit the next cell to provide information about your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1306671e-9f9e-402c-8211-1578fd1c5768"},"outputs":[],"source":["# For classification models use the below.\n","parameters = {\n","    \"favourable_class\": [\"No Risk\"],\n","    \"unfavourable_class\": [\"Risk\"]\n","    }"]},{"cell_type":"markdown","metadata":{"id":"887133d5-f801-46c0-a55b-90a0efe23d2b"},"source":["## Specify the number of records which should be processed for Fairness\n","\n","The final piece of information that needs to be provided is the number of records (min_records) that should be used for computing the fairness. Fairness checks runs hourly.  If min_records is set to 5000, then every hour fairness checking will pick up the last 5000 records which were sent to the model for scoring and compute the fairness on those 5000 records.  Please note that fairness computation will not start till the time that 5000 records are sent to the model for scoring.\n","\n","If we set the value of \"min_records\" to a small number, then fairness computation will get influenced by the scoring requests sent to the model in the recent past. In other words, the model might be flagged as being biased if it is acting in a biased manner on the last few records, but overall it might not be acting in a biased manner.  On the other hand, if the \"min_records\" is set to a very large number, then we will not be able to catch model bias quickly. Hence the value of min_records should be set such that it is neither too small or too large.\n","\n","Please updated the next cell to specify a value for min_records."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"832dfd92-bcaa-4eff-bec3-d3699a991e7d"},"outputs":[],"source":["# min_records = <Minimum number of records to be considered for preforming scoring>\n","min_records = 95\n","# max_records = <Maximum number of records to be considered while computing fairness> [OPTIONAL]\n","max_records = None"]},{"cell_type":"markdown","metadata":{"id":"e8c3fe64-274f-44f0-a27e-1c494357db74"},"source":["## End of Input \n","\n","You need not edit anything beyond this point.  Run the notebook and go to the very last cell.  There will be a link to download the JSON file (called: \"Download training data distribution JSON file\").  Download the file and upload it using the IBM AI OpenScale GUI.\n","\n","*Note: drop_na parameter of TrainingStats object should be set to 'False' if NA values are taken care while reading the training data in the above cells*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd7c1c0d-3f00-4b84-8c42-4d6bc6d29f24"},"outputs":[],"source":["from ibm_watson_openscale.utils.training_stats import TrainingStats\n","\n","enable_explainability = service_configuration_support.get(\"enable_explainability\")\n","enable_fairness = service_configuration_support.get(\"enable_fairness\")\n","\n","if enable_explainability or enable_fairness:\n","    fairness_inputs = None\n","    if enable_fairness:\n","        fairness_inputs = {\n","                \"fairness_attributes\": fairness_attributes,\n","                \"min_records\" : min_records,\n","                \"favourable_class\" :  parameters[\"favourable_class\"],\n","                \"unfavourable_class\": parameters[\"unfavourable_class\"]\n","            }\n","        if max_records is not None:\n","            fairness_inputs[\"max_records\"] = max_records\n","    \n","    input_parameters = {\n","        \"label_column\": training_data_info[\"class_label\"],\n","        \"feature_columns\": training_data_info[\"feature_columns\"],\n","        \"categorical_columns\": training_data_info[\"categorical_columns\"],\n","        \"fairness_inputs\": fairness_inputs,  \n","        \"problem_type\" : model_type  \n","    }\n","\n","    training_stats = TrainingStats(data_df,input_parameters, explain=enable_explainability, fairness=enable_fairness, drop_na=True)\n","    config_json = training_stats.get_training_statistics()\n","    config_json[\"notebook_version\"] = VERSION\n","#print(config_json)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00413499e9a04c7c8ced70476ae1ab57"},"outputs":[],"source":["print(config_json)"]},{"cell_type":"markdown","metadata":{"id":"db6cf2d5-cef4-4cf8-b60b-9db685ac918c"},"source":["## [Optional] Score Function\n","\n","This is required if you are configuring :\n","- Drift (for classification models), and/or \n","- Explainability (for headless subscriptions)\n","\n","Please update the score function which will be used for generating drift detection model which will used for drift detection. Also, if you have a headless subscription, this will be used to generate explain perturbations archive which be used for explanations. \n","\n","The output of the score function should be a 2 arrays :\n","1. Array of probabilities\n","2. Array of model prediction\n","\n","\n","Please note:\n","- User is expected to make sure that the data type of the \"class label\" column selected and the prediction column are same . For eg : If class label is numeric , the prediction array should also be numeric\n","- Each entry of a probability array should have all the probabities of the unique class lable .\n","  For eg: If the model_type=multiclass and unique class labels are A, B, C, D . Each entry in the probability array should be a array of size 4 . Eg : [ [0.50,0.30,0.10,0.10] ,[0.40,0.20,0.30,0.10]...]\n","- **Please update the score function below with the help of templates documented [here](https://github.com/IBM/watson-openscale-samples/blob/main/training%20statistics/Score%20function%20templates%20for%20drift%20detection.md)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb7f505e63b744c4851bc2d93ea3876e"},"outputs":[],"source":["import json\n","from ibm_watson_machine_learning import APIClient\n","\n","wml_client = APIClient(WML_CREDENTIALS)\n","wml_client.version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7559cccf5b6c40bb861cda1fa76c18da"},"outputs":[],"source":["wml_client.set.default_space(space_uid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"117f91b7-7388-4e08-9e30-c18aeca902ee"},"outputs":[],"source":["#Update score function\n","def score(training_data_frame):\n","      \n","    #The data type of the label column and prediction column should be same .\n","    #User needs to make sure that label column and prediction column array should have the same unique class labels\n","    prediction_column_name = \"predictedLabel\"\n","    probability_column_name = \"probability\"\n","        \n","    feature_columns = list(training_data_frame.columns)\n","    training_data_rows = training_data_frame[feature_columns].values.tolist()\n","    \n","    payload_scoring = {\n","      wml_client.deployments.ScoringMetaNames.INPUT_DATA: [{\n","           \"fields\": feature_columns,\n","           \"values\": [x for x in training_data_rows]\n","      }]\n","    }\n","\n","    score = wml_client.deployments.score(deployment_uid, payload_scoring)\n","    score_predictions = score.get('predictions')[0]\n","\n","    prob_col_index = list(score_predictions.get('fields')).index(probability_column_name)\n","    predict_col_index = list(score_predictions.get('fields')).index(prediction_column_name)\n","\n","    if prob_col_index < 0 or predict_col_index < 0:\n","        raise Exception(\"Missing prediction/probability column in the scoring response\")\n","\n","    import numpy as np\n","    probability_array = np.array([value[prob_col_index] for value in score_predictions.get('values')])\n","    prediction_vector = np.array([value[predict_col_index] for value in score_predictions.get('values')])\n","\n","    return probability_array, prediction_vector"]},{"cell_type":"markdown","metadata":{"id":"de620e2b-e5c4-4131-8710-076d5cc32d0c"},"source":["## [Optional] Generate explain perturbations archive\n","\n","This is required only for `headless` subscriptions, i.e., subscriptions which are configured without a REST endpoint for scoring needs. For explain to work in such scenarios, you must run following code snippet which generates and scores perturbations required by explainability service to function correctly.\n","\n","Output of this is an explainability perturbations archive which must be uploaded to IBM Watson OpenScale during explain monitor configuration."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7a25f72e-e8dd-4c4b-913e-ad005ef4dfd6"},"outputs":[],"source":["# Generate perturbations archive for headless subscriptions\n","if enable_explainability:\n","    import pandas as pd\n","    from ibm_wos_utils.explainability.utils.perturbations import Perturbations\n","    from ibm_wos_utils.joblib.utils.notebook_utils import create_archive\n","\n","    perturbations=Perturbations(training_stats=config_json.get(\"explainability_configuration\"), problem_type=model_type)\n","    perturbs_df = perturbations.generate_perturbations()\n","    perturbs_df.to_csv(\"perturbations.csv\",index=False)\n","\n","    # use score function to score generated perturbations\n","    predict_probability = score(perturbs_df)\n","    scored_perturbations = pd.DataFrame(\n","        {\n","            'probability': predict_probability[0].tolist(),\n","            'predicted_label': predict_probability[1].tolist()\n","        }\n","    )\n","\n","    # generate archive using scored perturbations and provide a link to download\n","    display(create_archive(scored_perturbations.to_csv(index=False), \"perturbations.csv\", \"explainability\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecfa450a-8847-478a-993f-8ed192f75417"},"outputs":[],"source":["import json\n","\n","print(\"Finished generating training distribution data\")\n","\n","# Create a file download link\n","import base64\n","from IPython.display import HTML\n","\n","def create_download_link( title = \"Download training data distribution JSON file\", filename = \"training_distribution.json\"):  \n","    if enable_explainability or enable_fairness:\n","        output_json = json.dumps(config_json, indent=2)\n","        b64 = base64.b64encode(output_json.encode())\n","        payload = b64.decode()\n","        html = '<a download=\"{filename}\" href=\"data:text/json;base64,{payload}\" target=\"_blank\">{title}</a>'\n","        html = html.format(payload=payload,title=title,filename=filename)\n","        return HTML(html)\n","    else:\n","        print(\"No download link generated as fairness/explainability services are disabled.\")\n","\n","create_download_link()"]},{"cell_type":"markdown","metadata":{"id":"d500056c-f887-47d9-b8ec-b9de3988f31e"},"source":["## Drift configuration archive generation\n","\n","Following code snippet is used to generate artefacts required for configuring drift identification for a model in IBM Watson OpenScale. Output is a drift archive which contains:\n","\n","- Drift Detection Model (used for Accuracy Drift detection for classification models)\n","- Data Constraints (used for Data Consistency Drift detection for classification/regression models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6fe91027-7c40-424b-bdb7-ccd718853ed2"},"outputs":[],"source":["#Generate drift detection model\n","from ibm_wos_utils.drift.drift_trainer import DriftTrainer\n","enable_drift = service_configuration_support.get(\"enable_drift\")\n","if enable_drift:\n","    drift_detection_input = {\n","        \"feature_columns\":training_data_info.get(\"feature_columns\"),\n","        \"categorical_columns\":training_data_info.get(\"categorical_columns\"),\n","        \"label_column\": training_data_info.get(\"class_label\"),\n","        \"problem_type\": model_type\n","    }\n","    \n","    drift_trainer = DriftTrainer(data_df,drift_detection_input)\n","    if model_type != \"regression\":\n","        #Note: batch_size can be customized by user as per the training data size\n","        drift_trainer.generate_drift_detection_model(score, batch_size=data_df.shape[0], check_for_ddm_quality=False)\n","    \n","    #Note:\n","    # - Two column constraints are not computed beyond two_column_learner_limit(default set to 200)\n","    # - Categorical columns with large (determined by categorical_unique_threshold; default > 0.8) number of unique values relative to total rows in the column are discarded. \n","    #User can adjust the value depending on the requirement\n","\n","    # user_overrides - Used to override drift constraint learning to selectively learn \n","    # constraints on feature columns. Its a list of configuration, each specifying \n","    # whether to learn distribution and/or range constraint on given set of columns.\n","    # First configuration of a given column would take preference.\n","    # \n","    # \"constraint_type\" can have two possible values : single|double - signifying \n","    # if this configuration is for single column or two column constraint learning.\n","    #\n","    # \"learn_distribution_constraint\" : True|False - signifying whether to learn \n","    # distribution constraint for given config or not.\n","    #\n","    # \"learn_range_constraint\" : True|False - signifying whether to learn range \n","    # constraint for given config or not. Only applicable to numerical feature columns.\n","    # \n","    # \"features\" : [] - provides either a list of feature columns to be governed by \n","    # given configuration for constraint learning.\n","    # Its a list of strings containing feature column names if \"constraint_type\" is \"single\".\n","    # Its a list of list of strings containing feature column names if \"constraint_type\" if \n","    # \"double\". If only one column name is provided, all of the two column constraints \n","    # involving this column will be dictated by given configuration during constraint learning.\n","    # This list is case-insensitive.\n","    #\n","    # In the example below, first config block says do not learn distribution and range single \n","    # column constraints for features \"MARITAL_STATUS\", \"PROFESSION\", \"IS_TENT\" and \"age\".\n","    # Second config block says do not learn distribution and range two column constraints \n","    # where \"IS_TENT\", \"PROFESSION\", and \"AGE\" are one of the two columns. Whereas, specifically, \n","    # do not learn two column distribution and range constraint on combination of \"MARITAL_STATUS\" \n","    # and \"PURCHASE_AMOUNT\".\n","    # \"user_overrides\"= [\n","    #     {\n","    #         \"constraint_type\": \"single\",\n","    #         \"learn_distribution_constraint\": False,\n","    #         \"learn_range_constraint\": False,\n","    #         \"features\": [\n","    #           \"MARITAL_STATUS\",\n","    #           \"PROFESSION\",\n","    #           \"IS_TENT\",\n","    #           \"age\"\n","    #         ]\n","    #     },\n","    #     {\n","    #         \"constraint_type\": \"double\",\n","    #         \"learn_distribution_constraint\": False,\n","    #         \"learn_range_constraint\": False,\n","    #         \"features\": [\n","    #           [\n","    #             \"IS_TENT\"\n","    #           ],\n","    #           [\n","    #             \"MARITAL_STATUS\"\n","    #             \"PURCHASE_AMOUNT\"\n","    #           ],\n","    #           [\n","    #             \"PROFESSION\"\n","    #           ],\n","    #           [\n","    #             \"AGE\"\n","    #           ]\n","    #         ]\n","    #     }\n","    # ]\n","    \n","    drift_trainer.learn_constraints(\n","        two_column_learner_limit=200, categorical_unique_threshold=0.8, user_overrides=[])\n","    drift_trainer.create_archive()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d53e50ee-35b4-4f7a-a8fe-17d2c1b57f7b"},"outputs":[],"source":["#Generate a download link for drift detection model\n","from IPython.display import HTML\n","import base64\n","import io\n","\n","def create_download_link_for_ddm( title = \"Download Drift detection model\", filename = \"drift_detection_model.tar.gz\"):  \n","    \n","    #Retains stats information    \n","    if enable_drift:\n","        with open(filename,\"rb\") as file:\n","            ddm = file.read()\n","        b64 = base64.b64encode(ddm)\n","        payload = b64.decode()\n","        \n","        html = '<a download=\"{filename}\" href=\"data:text/json;base64,{payload}\" target=\"_blank\">{title}</a>'\n","        html = html.format(payload=payload,title=title,filename=filename)\n","        return HTML(html)\n","    else:\n","        print(\"Drift Detection is not enabled. Please enable and rerun the notebook\")\n","\n","create_download_link_for_ddm()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad85db0c526c4894877e442f7380084f"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
